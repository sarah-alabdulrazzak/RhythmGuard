{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Load Data, Remove NaN & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "take_log_PTT = 0 # if not log, then all values are positive & the outliers are as defined\n",
    "Remove_HR_Outliers = 1 # =1 if required more constraints on HR ( 54.4 < HR < 155.8) \n",
    "Remove_PTT_Outliers = 1\n",
    "Remove_BP_Outliers = 1\n",
    "\n",
    "Remove_PTTm_Outliers = 0 #(PATf)\n",
    "Remove_PTTh_Outliers = 0 #(PPG Max-to-Min)\n",
    "\n",
    "\n",
    "All_Instants_Data2 = pd.read_csv('Extracted_Instants_Parameters_8secWindow_PTTm_PTTh_MAP_210621.csv')\n",
    "All_Instants_Data2.dropna(inplace=True)\n",
    "All_Instants_Data = All_Instants_Data2\n",
    "\n",
    "if take_log_PTT != 1:\n",
    "    All_Instants_Data['PTT'] = np.exp(All_Instants_Data['PTT']) ################ NOT LOG ANYMORE # By commenting this, it is log\n",
    "    All_Instants_Data['PTTm'] = np.exp(All_Instants_Data['PTTm'])\n",
    "\n",
    "# Removing BP Outliers\n",
    "if Remove_BP_Outliers == 1:\n",
    "    cond_BP = ((All_Instants_Data['SBP']<180) & (All_Instants_Data['SBP']>80)) & ((All_Instants_Data['DBP']<130) & (All_Instants_Data['DBP']>60))\n",
    "    All_Instants_Data= All_Instants_Data.loc[cond_BP, ['PTTh','PTTm','PTT','HR','SBP', 'DBP','MAP']]\n",
    "\n",
    "# Removing HR Outliers\n",
    "if Remove_HR_Outliers == 1: \n",
    "    cond_HR = ((All_Instants_Data['HR']>54.4) & (All_Instants_Data['HR']<155.8))\n",
    "    All_Instants_Data= All_Instants_Data.loc[cond_HR, ['PTTh','PTTm','PTT','HR','SBP', 'DBP','MAP']]\n",
    "    \n",
    "# Removing PTT Ouliers (outlier if PTT>1.5) # So far, considering PTT<0.5 range gave the best result\n",
    "if Remove_PTT_Outliers == 1: \n",
    "    cond_PTT = (All_Instants_Data['PTT']<0.4) #& (All_Instants_Data['PTT']>0.2)#& (All_Instants_Data['PTT']>.015) #### KEEP <0.4 only ##################\n",
    "    All_Instants_Data= All_Instants_Data.loc[cond_PTT, ['PTTh','PTTm','PTT','HR','SBP', 'DBP','MAP']]\n",
    "    \n",
    "# Removing PTTm (PATf) Outliers\n",
    "if Remove_PTTm_Outliers == 1: \n",
    "    cond_PTTm = ((All_Instants_Data['PTTm']>0.7) & (All_Instants_Data['PTTm']<1.5))\n",
    "    All_Instants_Data= All_Instants_Data.loc[cond_PTTm, ['PTTh','PTTm','PTT','HR','SBP', 'DBP','MAP']]\n",
    "    \n",
    "# Removing PTTh (PPG Max-to-Min) Outliers\n",
    "if Remove_PTTh_Outliers == 1: \n",
    "    cond_PTTh = ((All_Instants_Data['PTTh']>1) & (All_Instants_Data['PTTh']<2))\n",
    "    All_Instants_Data= All_Instants_Data.loc[cond_PTTh, ['PTTh','PTTm','PTT','HR','SBP', 'DBP','MAP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from FilesfnCopy import RemoveGarbageEncodeObjects, display_scores\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from datetime import datetime\n",
    "import m2cgen as m2c\n",
    "import joblib # to save: joblib.dump(model, model_file) .. to load: xyz = joblib.load(\"model_name_as_saved.pkl\")\n",
    "\n",
    "\n",
    "Results_file = TARGET+'_Results_'+'.txt'\n",
    "TARGET = 'SBP' # SBP or DBP or MAP\n",
    "Reg_Model_vec = ['LR', 'RF', 'SVM', 'DT']\n",
    "temp_data = All_Instants_Data.loc[:, ['PTTh','PTTm','PTT','HR']]\n",
    "train_copy2_tr, test_copy_tr, train_labels, test_labels = train_test_split(temp_data, All_Instants_Data[TARGET], test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "for Reg_Model in Reg_Model_vec:\n",
    "    C_Outputs = pd.DataFrame()\n",
    "    # Setting Models', Var's, Files', and Graphs' names to be saved\n",
    "    \n",
    "    CDF_file = TARGET + '_Error_CDF_' + Reg_Model + '.svg'\n",
    "    Test_Error_file = TARGET + '_Test_Error_' + Reg_Model + '.pkl'\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(len(test_copy_tr.index)):\n",
    "        new_str = str(test_copy_tr['PTTh'].iloc[i]) + str(test_copy_tr['PTTm'].iloc[i]) + str(test_copy_tr['PTT'].iloc[i]) + ',' + str(test_copy_tr['HR'].iloc[i]) \n",
    "        \n",
    "        ##################################################################################\n",
    "        # Now apply to the C code, and get the prediction & inference time\n",
    "        str_from_C = recvFromC()\n",
    "        HOW TO SEND STRING TO A C FUNCTION, SPLIT IT THERE, AND USE IT WITH THE CORRESPONDING MODEL??\n",
    "        ##################################################################################\n",
    "        \n",
    "        chunks = str_from_C.split(',')\n",
    "        Pred = float(chunks[0])\n",
    "        infTime = int(chunks[1]) \n",
    "        Subset_DF = pd.DataFrame({'Pred':[Pred],'Inf_Time':[infTime]})\n",
    "        C_Outputs = MCU_pred.append(Subset_DF, ignore_index=True)\n",
    "    \n",
    "    # Errors, ME, MAE, std Calculations:\n",
    "    \n",
    "    Test_Error = test_labels - C_Outputs['Pred']\n",
    "    Test_ME = np.mean(Test_Error)\n",
    "    Inf_Times_avg = np.mean(C_Outputs['Inf_Time'])\n",
    "    Test_std = np.std(Test_Error)\n",
    "    Test_MAE = np.mean(abs(Test_Error))\n",
    "    joblib.dump(Test_Error, Test_Error_file)\n",
    "    \n",
    "    # Writing Results in Text File: \n",
    "    textfile = open(Results_file, 'a')\n",
    "    textfile.write('Results for ' + Reg_Model + '\\n')\n",
    "    textfile.write('Test ME: ' + str(Test_ME) + '\\n')\n",
    "    textfile.write('Test Std: ' + str(Test_std) + '\\n')\n",
    "    textfile.write('Test MAE: ' + str(Test_MAE) + '\\n')\n",
    "    textfile.write('Average Inference Time: ' + str(Inf_Times_avg) + '\\n')\n",
    "    textfile.write('=========================================' + '\\n')\n",
    "    textfile.close()\n",
    "    \n",
    "    # Plot & Save CDF of Error\n",
    "    fig, ax = plt.subplots(figsize=(12, 8));\n",
    "    ax.hist(abs(Test_Error), 500, density=1, histtype='step', cumulative=True, label='Empirical');\n",
    "    plt.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dashdot', lw=1.5)\n",
    "    #minor grid lines\n",
    "    plt.minorticks_on()\n",
    "    plt.xlabel('Error (mmHg)')\n",
    "    plt.ylabel('Imperical CDF')\n",
    "    plt.title('CDF of %s Estimation Error Using %s' %(TARGET, Reg_Model))\n",
    "    plt.grid(b=True, which='minor', color='beige', alpha=0.8, ls='-', lw=1)\n",
    "    plt.savefig(CDF_file, format='svg', dpi=1200)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "void parseData() {\n",
    "\n",
    "    // split the data into its parts\n",
    "    \n",
    "  char * strtokIndx; // this is used by strtok() as an index\n",
    "    \n",
    "  strtokIndx = strtok(inputBuffer, \",\"); // this continues where the previous call left off\n",
    "  PTT = atof(strtokIndx);     // convert this part to a float .. PTT\n",
    "  \n",
    "  strtokIndx = strtok(NULL, \",\"); \n",
    "  HR = atof(strtokIndx);     // convert this part to a float .. HR\n",
    "\n",
    "}\n",
    "\n",
    "//=============\n",
    "void PredictSBP() {\n",
    "\tSBP = ((160.85850307659024) + ((PTT) * (-3.787763844588624))) + ((HR) * (-0.28774280257155976));\n",
    "}\n",
    "\n",
    "\n",
    "//===================\n",
    "\n",
    "startMicros = micros();\n",
    "  PredictSBP();\n",
    "  totMicros = micros() - startMicros;\n",
    "\n",
    "//=============\n",
    "\n",
    "void replyToPC() {\n",
    "\n",
    "  if (newDataFromPC) {\n",
    "    newDataFromPC = false;\n",
    "    Serial.print(\"<\");\n",
    "    Serial.print(SBP);\n",
    "    Serial.print(\",\");\n",
    "    Serial.print(DBP);\n",
    "\tSerial.print(\",\");\n",
    "    Serial.print(totMicros);\n",
    "    Serial.println(\">\");\n",
    "  }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py371_sklearn0201",
   "language": "python",
   "name": "py371_sklearn0201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
